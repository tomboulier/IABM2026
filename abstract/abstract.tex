\documentclass{IABM2026}

\IABMtitle{Influence de la variabilité des jeux de données d'entraînement et
performance des modèles génératifs en imagerie médicale : une étude préliminaire sur MedMNIST}
\IABMauthors{T. Boulier\textsuperscript{1,2}}
\IABMaffiliations{%
\textsuperscript{1}Pôle Anesthésie-Réanimation, CHU Grenoble Alpes, Grenoble, France \\
\textsuperscript{2}Service MISIT, Entrepôt de Données de Santé PREDIMED,
CHU Grenoble Alpes, Grenoble, France}
\IABMstatus{\begin{itemize}
		\item[$\bullet$] Ce travail est en cours
	\end{itemize}}

\begin{document}

\maketitle

\hrule height 1pt

\section*{Résumé}

\textbf{Contexte et motivation.}
L'entraînement de modèles génératifs \cite{ddpm,foster2023generative} en imagerie
médicale soulève des enjeux d'optimisation des ressources : coût computationnel et
empreinte environnementale \cite{strubell2019energy} d'une part, et principe de
minimisation des données imposé par le RGPD \cite{rgpd} d'autre part. Pouvoir
estimer a priori la difficulté d'apprentissage d'un jeu de données permettrait de
mieux calibrer les ressources nécessaires. Nous avons formulé l'hypothèse que la
variabilité intrinsèque d'un jeu de données pourrait constituer un tel indicateur
prédictif de la qualité de génération. En particulier, des jeux de données plus
homogènes pourraient faciliter l'apprentissage du modèle génératif.

\textbf{Méthode.}
Nous proposons un cadre de développement open source, disponible sur
GitHub\footnote{\url{https://github.com/tomboulier/IABM2026}}, permettant de
mesurer (1) la variabilité d'un jeu de données et (2) la similarité entre images
réelles et générées. Le code, structuré selon les principes de la Clean
Architecture \cite{cleanarchitecture}, est indépendant des frameworks
d'apprentissage : le chargement des données s'appuie sur MedMNIST
\cite{medmnistv2} via PyTorch, tandis que le modèle de diffusion DDPM \cite{ddpm}
est implémenté en TensorFlow, adapté de \cite{foster2023generative}. Cette
architecture modulaire permet d'intégrer d'autres modèles génératifs ou métriques.
La variabilité est quantifiée par la distance quadratique moyenne (DQM) des
vecteurs de caractéristiques extraits par un ResNet-18 \cite{resnet} pré-entraîné
sur ImageNet par rapport au centroïde du jeu de données. La similarité est évaluée
via le score FID \cite{fid}.

\textbf{Résultats préliminaires.}
Nous avons entraîné des modèles DDPM (1 itération, images 28$\times$28) sur 9 jeux
de données 2D de MedMNIST couvrant diverses modalités : microscopie, radiographie
thoracique, rétinographie, mammographie, scanners (coupes axiales, coronales,
sagittales) et photographie (dermatologie). Les expériences ont été réalisées sur
une station de travail équipée d'un processeur Intel Core i7-10850H, 32 Go de RAM
et un GPU NVIDIA Quadro T1000 (4 Go). Les temps d'entraînement varient de quelques
minutes à environ 2 heures par itération selon la taille du jeu de données. Les
résultats sont présentés dans le tableau 1 et la figure 1. Les valeurs de
variabilité s'échelonnent de 67,0 (TissueMNIST) à 135,1 (OrganAMNIST), et les
scores FID de 138,9 (OrganCMNIST) à 574,0 (RetinaMNIST).

\textbf{Discussion et perspectives.}
Contrairement à notre hypothèse initiale, nous n'observons pas de corrélation
claire entre variabilité et qualité de génération. Le cas de RetinaMNIST est
particulièrement intéressant : malgré une variabilité modérée (85,0), ce jeu de
données présente le pire score FID, suggérant que la complexité structurelle des
images dépasse la simple mesure de variance des caractéristiques. Ces résultats
préliminaires indiquent que la relation entre diversité d'un jeu de données et
facilité d'apprentissage génératif est plus complexe qu'anticipée. Plusieurs
limites doivent être considérées : l'entraînement limité à une seule itération, la
faible résolution des images (28$\times$28), et le choix de la métrique de
variabilité. Des tests exploratoires avec 10 itérations sur RetinaMNIST montrent
une amélioration visuelle notable par rapport au bruit observé en figure 1. Les
travaux en cours visent à mener des campagnes de calcul plus étendues sur une
plateforme de calcul haute performance, avec des entraînements plus longs, des
résolutions supérieures (64$\times$64, 128$\times$128), des métriques alternatives,
les jeux de données 3D de MedMNIST, ainsi que d'autres architectures génératives
telles que les GAN \cite{gan} et les VAE \cite{vae}.

\section*{Figures et Tableaux}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figure_comparison.pdf}
    \caption{Comparaison entre images réelles (gauche) et générées après 1
    itération (droite) pour trois datasets représentatifs. OrganCMNIST (FID=139)
    produit des formes reconnaissables, BloodMNIST (FID=313) préserve la
    structure cellulaire, tandis que RetinaMNIST (FID=574) génère du bruit
    malgré une variabilité modérée.}
\end{figure}

\begin{table}[h!]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Dataset} & \textbf{Samples} & \textbf{Variabilité} & \textbf{FID} $\downarrow$ \\
        \hline
        TissueMNIST & 165\,466 & 67,0 & 142,5 \\
        PneumoniaMNIST & 4\,708 & 71,9 & 164,9 \\
        RetinaMNIST & 1\,080 & 85,0 & \textbf{574,0} \\
        BreastMNIST & 546 & 93,3 & 296,3 \\
        BloodMNIST & 11\,959 & 96,8 & 313,2 \\
        OrganCMNIST & 12\,975 & 122,1 & \textbf{138,9} \\
        OrganSMNIST & 13\,932 & 123,3 & 143,8 \\
        DermaMNIST & 7\,007 & 123,7 & 175,8 \\
        OrganAMNIST & 34\,561 & 135,1 & 191,2 \\
        \hline
    \end{tabular}
    \caption{Variabilité (DQM ResNet-18) et score FID pour 9 datasets MedMNIST.
    Un FID plus bas indique une meilleure qualité de génération.}
\end{table}

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}
